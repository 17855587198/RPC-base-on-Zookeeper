# Zrpc框架压测设计与实现

## 1. 压测整体架构

### 1.1 压测目标
- 验证RPC框架的并发处理能力
- 测试分布式服务间的协作性能
- 评估缓存服务的命中率和性能
- 检验系统在高负载下的稳定性

### 1.2 压测架构图
```
客户端压测程序 (Zclient.cc)
├── 多线程并发模拟 (10个线程)
├── 原子计数器统计 (success_count, fail_count)
├── 时间测量 (start_time, end_time)
└── 三种测试模式
    ├── 用户服务压测 (--user)
    ├── 缓存服务压测 (--cache)
    └── 集成业务压测 (--integrated)

服务端 (Zserver.cc)
├── UserService (登录、注册、用户资料查询)
├── CacheService (缓存操作、统计信息)
└── Muduo网络库 (多线程处理并发请求)
```

## 2. 核心压测机制

### 2.1 多线程并发模拟
```cpp
// 核心实现：创建多个线程模拟并发客户端
const int thread_count = 10;       // 并发线程数
const int requests_per_thread = 20; // 每线程请求数

for (int i = 0; i < thread_count; i++) {
    threads.emplace_back([i, &success_count, &fail_count, requests_per_thread]() {
        for (int j = 0; j < requests_per_thread; j++) {
            test_integrated_business(i, success_count, fail_count);
        }
    });
}
```

**设计思想**：
- 每个线程模拟一个独立的客户端
- 通过Lambda表达式捕获共享计数器
- 使用线程ID区分不同客户端的操作

### 2.2 原子操作保证统计准确性
```cpp
std::atomic<int> success_count(0); // 原子计数器
std::atomic<int> fail_count(0);    // 避免竞态条件

// 在每个线程中安全地更新计数
success_count++;  // 原子递增操作
fail_count++;     // 线程安全
```

**关键优势**：
- 无需加锁，性能更高
- 保证多线程下计数的准确性
- 避免了传统锁带来的性能开销

### 2.3 连接管理和心跳保活
```cpp
// 每个线程创建独立的连接通道
ZrpcChannel* channel = new ZrpcChannel(false);
channel->EnableHeartbeat(true);  // 启用心跳检测

// 超时控制
Zrpccontroller controller;
controller.SetTimeout(15000);  // 15秒超时
```

**实现细节**：
- 每线程独立连接，避免连接争用
- 心跳机制确保连接可用性
- 超时控制防止请求无限等待

## 3. 三种压测模式详解

### 3.1 用户服务压测 (--user)
```cpp
void send_request(int thread_id, std::atomic<int> &success_count, std::atomic<int> &fail_count) {
    // 测试登录接口
    Kuser::LoginRequest request;
    request.set_name("zhangsan");
    request.set_pwd("123456");
    
    stub.Login(&controller, &request, &response, nullptr);
    
    // 测试注册接口
    Kuser::RegisterRequest req;
    req.set_id(100000);
    req.set_name("Zrpc");
    req.set_pwd("1111111");
    
    stub.Register(nullptr, &req, &rsp, nullptr);
}
```

**测试内容**：
- Login接口的并发处理能力
- Register接口的性能表现
- RPC序列化/反序列化性能
- 网络通信开销

### 3.2 缓存服务压测 (--cache)
```cpp
void test_cache_service(int thread_id, std::atomic<int> &success_count, std::atomic<int> &fail_count) {
    // 1. Set操作压测
    cache_stub.Set(&set_controller, &set_request, &set_response, nullptr);
    
    // 2. Get操作压测
    cache_stub.Get(&get_controller, &get_request, &get_response, nullptr);
    
    // 3. Exists操作压测
    cache_stub.Exists(&exists_controller, &exists_request, &exists_response, nullptr);
}
```

**测试指标**：
- 缓存读写性能 (Set/Get QPS)
- 并发访问下的数据一致性
- 缓存命中率统计
- 内存使用效率

### 3.3 集成业务压测 (--integrated)
```cpp
void test_integrated_business(int thread_id, std::atomic<int> &success_count, std::atomic<int> &fail_count) {
    // 1. 检查会话缓存
    cache_stub.Exists(&exists_controller, &exists_request, &exists_response, nullptr);
    
    if (!exists_response.exists()) {
        // 2. 用户登录
        user_stub.Login(&login_controller, &login_request, &login_response, nullptr);
        
        // 3. 缓存会话
        cache_stub.Set(&set_controller, &set_request, &set_response, nullptr);
    }
    
    // 4. 用户资料查询 + 缓存
    user_stub.GetUserProfile(&user_profile_controller, &user_profile_request, &user_profile_response, nullptr);
    cache_stub.Set(&profile_set_controller, &profile_set_request, &profile_set_response, nullptr);
}
```

**业务场景**：
- 用户登录 → 会话缓存 → 会话复用
- 用户资料查询 → 结果缓存 → 缓存命中
- 服务间协作的完整链路测试

## 4. 服务端并发处理机制

### 4.1 Muduo网络库多线程模型
```cpp
// 在 Zrpcprovider.cc 中
server->setThreadNum(4);  // 设置工作线程数
server->setConnectionCallback(...);  // 连接回调
server->setMessageCallback(...);     // 消息处理回调
```

**处理流程**：
1. 主线程负责接受连接
2. 工作线程池处理I/O事件
3. 业务线程处理RPC调用
4. 异步回调返回结果

### 4.2 缓存服务的并发优化
```cpp
// 在 CacheService.cc 中
std::shared_mutex cache_mutex_;  // 读写锁
std::atomic<int64_t> hit_count_{0};  // 原子统计

void Get(...) {
    std::shared_lock<std::shared_mutex> lock(cache_mutex_);  // 共享读锁
    // 多个读操作可以并发执行
}

void Set(...) {
    std::unique_lock<std::shared_mutex> lock(cache_mutex_);  // 独占写锁
    // 写操作互斥
}
```

**性能优化**：
- 读写锁允许多读单写
- 原子计数器避免锁开销
- 后台清理线程异步处理过期数据

## 5. 性能指标计算

### 5.1 QPS计算
```cpp
auto start_time = std::chrono::high_resolution_clock::now();
// ... 执行压测 ...
auto end_time = std::chrono::high_resolution_clock::now();

std::chrono::duration<double> elapsed = end_time - start_time;
double qps = (thread_count * requests_per_thread) / elapsed.count();
```

### 5.2 成功率统计
```cpp
int total_requests = thread_count * requests_per_thread;
double success_rate = (double)success_count / total_requests * 100;
```

### 5.3 缓存命中率
```cpp
// 在缓存服务中统计
double hit_rate = (double)hit_count / (hit_count + miss_count) * 100;
```

## 6. 压测执行步骤

### 6.1 环境准备
```bash
# 1. 启动ZooKeeper
zkServer.sh start

# 2. 编译项目
cd d:\sharedFolder\Zrpc\Zrpc\build
cmake .. && make -j4
```

### 6.2 启动服务
```bash
# 启动RPC服务端
cd d:\sharedFolder\Zrpc\Zrpc\bin
./server -i test.conf
```

### 6.3 执行压测
```bash
# 集成业务压测
./client --integrated -i test.conf

# 用户服务压测
./client --user -i test.conf

# 缓存服务压测
./client --cache -i test.conf
```

## 7. 压测结果分析

### 7.1 关键指标
- **QPS**: 每秒处理请求数
- **成功率**: success_count / total_requests
- **平均响应时间**: elapsed_time / total_requests
- **并发能力**: 多线程下的性能表现

### 7.2 示例输出
```
=== integrated Test Results ===
Total requests: 200
Success count: 180
Fail count: 20
Elapsed time: 2.5 seconds
QPS: 80.0
```

### 7.3 性能调优建议
- 调整线程池大小
- 优化缓存过期策略
- 调整超时参数
- 使用连接池复用

## 8. 压测框架的扩展性

### 8.1 新增测试场景
可以轻松添加新的测试函数：
```cpp
void test_new_service(int thread_id, std::atomic<int> &success_count, std::atomic<int> &fail_count) {
    // 新的测试逻辑
}
```

### 8.2 参数化配置
```cpp
const int thread_count = 10;       // 可配置并发数
const int requests_per_thread = 20; // 可配置请求数
```

### 8.3 监控和日志
- 使用ZrpcLogger记录详细日志
- 支持不同日志级别
- 便于问题追踪和性能分析

## 9. 总结

这个压测框架的核心优势：

1. **真实模拟**：多线程模拟真实并发场景
2. **全面覆盖**：涵盖RPC、缓存、业务集成
3. **精确统计**：原子操作保证统计准确性
4. **易于扩展**：模块化设计，便于添加新场景
5. **性能优化**：读写锁、无锁编程、异步处理

通过这套压测系统，可以全面评估分布式RPC框架在高并发场景下的性能表现和稳定性。
